05/05/2023

ITERATIONS = 20
TIMESTEPS = 2048*20 = 40960

TIEMPO: 530.31 minutos

env.createEnv(nVehiculos = 30, nNodos = 100, maxNodeCapacity = 4, sameMaxNodeVehicles=True)
env.setIncreasingIsDone(ITERATIONS * TIMESTEPS)

CAMBIOS:
    - La ejecución se ha realizado en el servidor y ha tardado (aparentemente) bastante más que en local

NOTAS:
    - El principal objetivo de esta prueba era hacer un entrenamiento algo más largo que el de la prueba 006, y observar si el
      aprendizaje se "mantenía". En algoritmos de RL, al aproximarse a la máxima optimización, el algoritmo "deja" de aprender
      (lo que se muestra como una línea de reward más o menos horizontal), pero en ningún caso debería "desaprender", como ocurre aquí.
      
      Habría que mirar por qué sucede, y cómo arreglarlo. También sería interesante probar a hacer un entrenamiento con múltiples casos
      en los que estos vayan rotando/variando.